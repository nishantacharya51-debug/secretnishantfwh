<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1.0"/>
  <title>Secret ICT Call Room (Fixed + Effects + Nepali AI)</title>

  <style>
    body{font-family:Arial,sans-serif;background:#f2f2f2;margin:0;padding:16px;text-align:center}
    .card{max-width:980px;margin:0 auto;background:#fff;border-radius:14px;padding:14px;box-shadow:0 8px 24px rgba(0,0,0,.08)}
    h1{margin:8px 0 6px}
    .row{display:flex;gap:12px;flex-wrap:wrap;justify-content:center;align-items:flex-start}
    .col{flex:1;min-width:280px}
    input,select,button,textarea{font-size:16px}
    input,select,textarea{padding:10px;border:1px solid #ddd;border-radius:10px;width:100%;box-sizing:border-box}
    button{padding:10px 14px;border:0;border-radius:10px;background:#2563eb;color:#fff;cursor:pointer}
    button:hover{background:#1d4ed8}
    button.secondary{background:#111827}
    button.secondary:hover{background:#0b1220}
    button.danger{background:#dc2626}
    button.danger:hover{background:#b91c1c}
    .pill{display:inline-block;padding:6px 10px;border-radius:999px;background:#eef2ff;color:#3730a3;font-size:13px;margin:6px 0}
    .videos{display:flex;gap:12px;flex-wrap:wrap;justify-content:center}
    video,canvas{width:100%;max-width:440px;border-radius:14px;border:2px solid #111827}
    .controls{display:flex;gap:8px;flex-wrap:wrap;justify-content:center;margin-top:10px}
    .effects{margin-top:10px;text-align:left}
    .effects label{display:flex;gap:8px;align-items:center;margin:6px 0}
    .chatbox{height:220px;overflow:auto;border:1px solid #eee;border-radius:12px;padding:10px;text-align:left;background:#fafafa}
    .msg{margin:8px 0}
    .me{color:#111827}
    .peer{color:#0f766e}
    .bot{color:#7c3aed}
    .small{font-size:13px;color:#6b7280}
    .hidden{display:none}
  </style>

  <!-- Firebase compat (easiest for single-file) -->
  <script src="https://www.gstatic.com/firebasejs/9.22.0/firebase-app-compat.js"></script>
  <script src="https://www.gstatic.com/firebasejs/9.22.0/firebase-database-compat.js"></script>

  <!-- MediaPipe (Segmentation + FaceMesh) -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/selfie_segmentation.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
</head>

<body>
  <div class="card">
    <h1>Secret ICT Call Room</h1>
    <div class="pill" id="statusPill">Status: idle</div>

    <!-- STEP 1: Password gate (optional) -->
    <div id="gate">
      <p class="small">Enter password to open the call room UI.</p>
      <div class="row">
        <div class="col">
          <input id="password" type="password" placeholder="Password"/>
        </div>
        <div class="col" style="flex:0.4;min-width:180px">
          <button id="enterBtn">Enter</button>
        </div>
      </div>
      <p class="small">Default: <b>Nishant@123</b> (change it in code)</p>
      <hr/>
    </div>

    <!-- STEP 2: Room join -->
    <div id="app" class="hidden">
      <div class="row">
        <div class="col">
          <input id="roomId" placeholder="Room Code (share same code on both devices) e.g. m2968eras" />
          <div class="small" style="margin-top:6px;">
            Tip: One device clicks <b>Create/Join</b>, second device enters the <b>same Room Code</b> and clicks <b>Create/Join</b>.
          </div>
        </div>
        <div class="col" style="flex:0.6;min-width:240px;">
          <div class="controls" style="justify-content:flex-end">
            <button id="joinBtn">Create/Join</button>
            <button id="leaveBtn" class="danger">Leave</button>
          </div>
        </div>
      </div>

      <div class="videos" style="margin-top:12px;">
        <!-- Hidden raw local video (used for processing) -->
        <video id="localRaw" autoplay playsinline muted class="hidden"></video>

        <!-- Processed local preview -->
        <canvas id="localCanvas"></canvas>

        <!-- Remote -->
        <video id="remoteVideo" autoplay playsinline></video>
      </div>

      <div class="controls">
        <button id="startVideoBtn">Start Video</button>
        <button id="startVoiceBtn">Start Voice Only</button>
        <button id="shareBtn" class="secondary">Share Screen</button>
        <button id="hangupBtn" class="danger">End Call</button>
      </div>

      <div class="row" style="margin-top:14px;">
        <!-- Effects -->
        <div class="col effects">
          <h3 style="margin:6px 0;">Effects</h3>

          <label><input type="checkbox" id="fxGreen"/> Green background (AI)</label>
          <label><input type="checkbox" id="fxGlasses"/> Glasses overlay</label>
          <label><input type="checkbox" id="fxHat"/> Hat overlay</label>

          <label>
            Hair color:
            <select id="hairMode">
              <option value="off">Off</option>
              <option value="cool">Cool (hue shift)</option>
              <option value="warm">Warm (hue shift)</option>
            </select>
          </label>

          <label>
            Clothes tint:
            <select id="clothMode">
              <option value="off">Off</option>
              <option value="blue">Blue tint</option>
              <option value="green">Green tint</option>
              <option value="purple">Purple tint</option>
            </select>
          </label>

          <p class="small">
            Note: ‚Äúhair/clothes changer‚Äù here is a lightweight demo effect. Realistic AI outfit/hair replacement needs heavier models + GPU and is not stable on low-end phones.
          </p>
        </div>

        <!-- Chat + Nepali AI bot -->
        <div class="col">
          <h3 style="margin:6px 0;">Chat (with Nepali Voice + AI Bot)</h3>
          <div class="chatbox" id="chatBox"></div>

          <div class="row" style="margin-top:8px;">
            <div class="col">
              <input id="chatInput" placeholder="Type message in Nepali or English..." />
              <div class="small">AI will reply in Nepali if backend is connected.</div>
            </div>
            <div class="col" style="flex:0.5;min-width:220px;">
              <div class="controls" style="justify-content:flex-end">
                <button id="sendBtn">Send</button>
                <button id="voiceToggleBtn" class="secondary">Nepali Voice: ON</button>
              </div>
            </div>
          </div>

          <p class="small">
            AI Bot needs a backend endpoint: <b>/api/nepali-bot</b> (sample idea included in comments below).
          </p>
        </div>
      </div>

    </div>
  </div>

<script>
/* =========================
   0) BASIC SETTINGS
========================= */

// Password gate
const PASSWORD = "Nishant@123";

// Firebase config (PUT YOUR REAL CONFIG)
const firebaseConfig = {
  apiKey: "YOUR_API_KEY",
  authDomain: "YOUR_PROJECT.firebaseapp.com",
  databaseURL: "https://YOUR_PROJECT-default-rtdb.firebaseio.com",
  projectId: "YOUR_PROJECT",
  storageBucket: "YOUR_PROJECT.appspot.com",
  messagingSenderId: "YOUR_SENDER_ID",
  appId: "YOUR_APP_ID",
};
firebase.initializeApp(firebaseConfig);
const db = firebase.database();

// UI
const statusPill = document.getElementById("statusPill");
function setStatus(t){ statusPill.textContent = "Status: " + t; }

// Voice
let nepaliVoiceOn = true;

// WebRTC
let pc = null;
let localStreamRaw = null;
let localStreamToSend = null; // can be processed canvas stream or screen stream
let remoteStream = new MediaStream();
let isCaller = false;
let currentRoomId = null;
let roomRef = null;

// Elements
const gate = document.getElementById("gate");
const app = document.getElementById("app");
const enterBtn = document.getElementById("enterBtn");
const passwordInput = document.getElementById("password");

const joinBtn = document.getElementById("joinBtn");
const leaveBtn = document.getElementById("leaveBtn");
const roomIdInput = document.getElementById("roomId");

const localRawVideo = document.getElementById("localRaw");
const localCanvas = document.getElementById("localCanvas");
const remoteVideo = document.getElementById("remoteVideo");

const startVideoBtn = document.getElementById("startVideoBtn");
const startVoiceBtn = document.getElementById("startVoiceBtn");
const shareBtn = document.getElementById("shareBtn");
const hangupBtn = document.getElementById("hangupBtn");

const fxGreen = document.getElementById("fxGreen");
const fxGlasses = document.getElementById("fxGlasses");
const fxHat = document.getElementById("fxHat");
const hairMode = document.getElementById("hairMode");
const clothMode = document.getElementById("clothMode");

// Chat
const chatBox = document.getElementById("chatBox");
const chatInput = document.getElementById("chatInput");
const sendBtn = document.getElementById("sendBtn");
const voiceToggleBtn = document.getElementById("voiceToggleBtn");

/* =========================
   1) PASSWORD GATE
========================= */
enterBtn.onclick = () => {
  const val = passwordInput.value;
  if (val === PASSWORD) {
    gate.classList.add("hidden");
    app.classList.remove("hidden");
    setStatus("unlocked");
  } else {
    alert("Incorrect password!");
  }
};

/* =========================
   2) MEDIA PIPE SETUP
========================= */
const ctx = localCanvas.getContext("2d", { willReadFrequently: false });

// Overlay images (simple emoji-like PNG via canvas drawText fallback if fails)
const glassesImg = new Image();
glassesImg.src = "https://i.imgur.com/2yYayZk.png"; // replace with your own transparent PNG
const hatImg = new Image();
hatImg.src = "https://i.imgur.com/9Q9ZQZQ.png"; // replace with your own transparent PNG

// Selfie segmentation
const selfieSeg = new SelfieSegmentation({ locateFile: (f) => `https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/${f}`});
selfieSeg.setOptions({ modelSelection: 1 }); // 0 faster, 1 better

let latestSegMask = null;
selfieSeg.onResults((res) => { latestSegMask = res.segmentationMask; });

// FaceMesh for landmarks
const faceMesh = new FaceMesh({ locateFile: (f) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${f}`});
faceMesh.setOptions({
  maxNumFaces: 1,
  refineLandmarks: true,
  minDetectionConfidence: 0.5,
  minTrackingConfidence: 0.5
});

let latestFace = null;
faceMesh.onResults((res) => {
  latestFace = (res.multiFaceLandmarks && res.multiFaceLandmarks[0]) ? res.multiFaceLandmarks[0] : null;
});

async function startCamera(video=true, audio=true){
  // Raw camera
  localStreamRaw = await navigator.mediaDevices.getUserMedia({ video, audio });
  localRawVideo.srcObject = localStreamRaw;
  await localRawVideo.play();

  // Set canvas size
  const w = localRawVideo.videoWidth || 640;
  const h = localRawVideo.videoHeight || 480;
  localCanvas.width = w;
  localCanvas.height = h;

  // Start MediaPipe camera loop
  const mpCam = new Camera(localRawVideo, {
    onFrame: async () => {
      // Run segmentation + face landmarks
      await selfieSeg.send({ image: localRawVideo });
      await faceMesh.send({ image: localRawVideo });

      // Draw processed frame
      drawProcessedFrame();
    },
    width: w,
    height: h
  });
  mpCam.start();

  // Send processed stream (canvas capture) so remote also sees effects
  const canvasStream = localCanvas.captureStream(25);
  // Audio track should come from raw stream
  const audioTracks = localStreamRaw.getAudioTracks();
  if (audioTracks.length) canvasStream.addTrack(audioTracks[0]);

  localStreamToSend = canvasStream;
}

function drawProcessedFrame(){
  const w = localCanvas.width, h = localCanvas.height;

  // Base: draw camera
  ctx.save();
  ctx.clearRect(0,0,w,h);

  // 1) If green screen enabled, replace background using segmentation mask
  if (fxGreen.checked && latestSegMask) {
    // draw background (green)
    ctx.fillStyle = "#00ff66";
    ctx.fillRect(0,0,w,h);

    // draw person only
    ctx.globalCompositeOperation = "source-over";
    ctx.drawImage(localRawVideo, 0,0,w,h);

    // keep only person region using mask
    ctx.globalCompositeOperation = "destination-in";
    ctx.drawImage(latestSegMask, 0,0,w,h);

    // reset to draw overlays
    ctx.globalCompositeOperation = "source-over";
  } else {
    ctx.drawImage(localRawVideo, 0,0,w,h);
  }

  // 2) Hair effect (lightweight): apply a tinted rectangle on top area (demo)
  // This is not perfect ‚Äúhair changer‚Äù; it‚Äôs a simple stylized effect.
  if (hairMode.value !== "off") {
    ctx.save();
    ctx.globalAlpha = 0.18;
    if (hairMode.value === "cool") ctx.fillStyle = "#00aaff";
    if (hairMode.value === "warm") ctx.fillStyle = "#ff7a00";
    // top portion (approx hair zone)
    ctx.fillRect(0, 0, w, h*0.28);
    ctx.restore();
  }

  // 3) Clothes tint (lightweight): tint lower half region (demo)
  if (clothMode.value !== "off") {
    ctx.save();
    ctx.globalAlpha = 0.14;
    if (clothMode.value === "blue") ctx.fillStyle = "#1d4ed8";
    if (clothMode.value === "green") ctx.fillStyle = "#059669";
    if (clothMode.value === "purple") ctx.fillStyle = "#7c3aed";
    ctx.fillRect(0, h*0.45, w, h*0.55);
    ctx.restore();
  }

  // 4) Face overlays (glasses/hat) using landmarks when available
  if (latestFace) {
    const lm = latestFace;

    // helper: convert landmark to pixel
    const px = (p) => ({ x: p.x * w, y: p.y * h });

    // approximate glasses placement using eye landmarks
    // Left eye outer: 33, right eye outer: 263
    const left = px(lm[33]);
    const right = px(lm[263]);
    const centerX = (left.x + right.x) / 2;
    const centerY = (left.y + right.y) / 2;

    const eyeDist = Math.hypot(right.x - left.x, right.y - left.y);
    const angle = Math.atan2(right.y - left.y, right.x - left.x);

    // GLASSES
    if (fxGlasses.checked) {
      drawRotatedImage(glassesImg, centerX, centerY, eyeDist * 1.8, eyeDist * 0.65, angle);
      // fallback if img not loaded
      if (!glassesImg.complete) {
        ctx.save();
        ctx.font = `${Math.max(18, eyeDist*0.35)}px Arial`;
        ctx.fillText("üòé", centerX - 14, centerY + 10);
        ctx.restore();
      }
    }

    // HAT: use forehead-ish point 10 and chin 152 for scale
    const forehead = px(lm[10]);
    const chin = px(lm[152]);
    const faceH = Math.hypot(chin.x - forehead.x, chin.y - forehead.y);

    if (fxHat.checked) {
      const hatX = forehead.x;
      const hatY = forehead.y - faceH*0.22;
      drawRotatedImage(hatImg, hatX, hatY, faceH * 1.2, faceH * 0.9, angle);
      if (!hatImg.complete) {
        ctx.save();
        ctx.font = `${Math.max(18, faceH*0.35)}px Arial`;
        ctx.fillText("üé©", hatX - 14, hatY + 10);
        ctx.restore();
      }
    }
  }

  ctx.restore();
}

function drawRotatedImage(img, cx, cy, w, h, angle){
  if (!img || !img.complete) return;
  ctx.save();
  ctx.translate(cx, cy);
  ctx.rotate(angle);
  ctx.drawImage(img, -w/2, -h/2, w, h);
  ctx.restore();
}

/* =========================
   3) WEBRTC + FIREBASE SIGNALING
   Fix: both devices use SAME roomId.
   Caller = first who creates room (no offer yet)
   Callee = second who joins existing offer
========================= */

function makeRoomRef(roomId){
  return db.ref("webrtcRooms").child(roomId);
}

async function ensurePC(){
  if (pc) return;

  pc = new RTCPeerConnection({
    iceServers: [
      { urls: ["stun:stun.l.google.com:19302"] }
    ]
  });

  // Remote track
  remoteStream = new MediaStream();
  remoteVideo.srcObject = remoteStream;
  pc.ontrack = (e) => {
    e.streams[0].getTracks().forEach(t => remoteStream.addTrack(t));
  };

  // ICE -> Firebase
  pc.onicecandidate = (e) => {
    if (!e.candidate || !roomRef) return;
    const path = isCaller ? "callerCandidates" : "calleeCandidates";
    roomRef.child(path).push(e.candidate.toJSON());
  };
}

async function addLocalTracksToPC(){
  if (!localStreamToSend) throw new Error("Start camera first.");
  localStreamToSend.getTracks().forEach(track => pc.addTrack(track, localStreamToSend));
}

async function createOrJoin(){
  const roomId = (roomIdInput.value || "").trim();
  if (!roomId) return alert("Enter a Room Code.");

  currentRoomId = roomId;
  roomRef = makeRoomRef(roomId);
  setStatus("joining " + roomId);

  const snap = await roomRef.get();
  const data = snap.val();

  // Start camera (video+audio) by default if not started
  if (!localStreamRaw) {
    await startCamera(true, true);
  }

  await ensurePC();
  await addLocalTracksToPC();

  // If room has no offer -> we are caller
  if (!data || !data.offer) {
    isCaller = true;
    setStatus("caller (creating offer)");

    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);

    await roomRef.set({
      createdAt: Date.now(),
      offer: { type: offer.type, sdp: offer.sdp }
    });

    // Listen for answer
    roomRef.child("answer").on("value", async (s) => {
      const ans = s.val();
      if (!ans) return;
      if (!pc.currentRemoteDescription) {
        await pc.setRemoteDescription(new RTCSessionDescription(ans));
        setStatus("connected (answer received)");
      }
    });

    // Listen callee candidates
    roomRef.child("calleeCandidates").on("child_added", (s) => {
      const c = s.val();
      if (c) pc.addIceCandidate(new RTCIceCandidate(c));
    });

  } else {
    // Existing offer -> we are callee
    isCaller = false;
    setStatus("callee (answering)");

    await pc.setRemoteDescription(new RTCSessionDescription(data.offer));
    const answer = await pc.createAnswer();
    await pc.setLocalDescription(answer);

    await roomRef.child("answer").set({ type: answer.type, sdp: answer.sdp });

    // Listen caller candidates
    roomRef.child("callerCandidates").on("child_added", (s) => {
      const c = s.val();
      if (c) pc.addIceCandidate(new RTCIceCandidate(c));
    });

    setStatus("connected (answered)");
  }

  // Start chat listeners
  startChatListener();
}

/* =========================
   4) CALL CONTROLS
========================= */

joinBtn.onclick = () => createOrJoin().catch(err => {
  console.error(err);
  alert("Join error: " + err.message);
});

leaveBtn.onclick = () => cleanup(true);

startVideoBtn.onclick = async () => {
  if (!localStreamRaw) await startCamera(true, true);
  alert("Camera started. If already in room, re-join to send tracks cleanly.");
};

startVoiceBtn.onclick = async () => {
  if (!localStreamRaw) await startCamera(false, true); // audio only
  // If camera already running, disable video tracks
  if (localStreamRaw) localStreamRaw.getVideoTracks().forEach(t => t.enabled = false);
  alert("Voice-only enabled. If already in room, re-join to send tracks cleanly.");
};

shareBtn.onclick = async () => {
  try {
    const screen = await navigator.mediaDevices.getDisplayMedia({ video: true, audio: false });
    // Replace outgoing video track
    if (pc) {
      const sender = pc.getSenders().find(s => s.track && s.track.kind === "video");
      const screenTrack = screen.getVideoTracks()[0];
      if (sender && screenTrack) sender.replaceTrack(screenTrack);

      // show local preview as screen (optional)
      localRawVideo.srcObject = screen;
      localRawVideo.classList.remove("hidden");

      screenTrack.onended = () => {
        // revert to processed canvas video if available
        if (localStreamToSend) {
          const sender2 = pc.getSenders().find(s => s.track && s.track.kind === "video");
          const canvasVideoTrack = localStreamToSend.getVideoTracks()[0];
          if (sender2 && canvasVideoTrack) sender2.replaceTrack(canvasVideoTrack);
        }
      };
    }
  } catch (e) {
    alert("Screen share failed: " + e.message);
  }
};

hangupBtn.onclick = () => cleanup(false);

async function cleanup(removeRoom){
  setStatus("cleaning up");

  // stop listeners
  if (roomRef) {
    roomRef.child("answer").off();
    roomRef.child("calleeCandidates").off();
    roomRef.child("callerCandidates").off();
    roomRef.child("chat").off();
  }

  // close pc
  if (pc) {
    try { pc.close(); } catch {}
    pc = null;
  }

  // stop streams
  if (localStreamRaw) {
    localStreamRaw.getTracks().forEach(t => t.stop());
    localStreamRaw = null;
  }
  if (localStreamToSend) {
    localStreamToSend.getTracks().forEach(t => {
      // do not double-stop same audio track if shared
      try { t.stop(); } catch {}
    });
    localStreamToSend = null;
  }

  remoteStream = new MediaStream();
  remoteVideo.srcObject = remoteStream;

  // remove room data only when user clicks Leave (optional)
  if (removeRoom && roomRef) {
    await roomRef.remove();
  }

  roomRef = null;
  currentRoomId = null;
  isCaller = false;

  setStatus("idle");
}

/* =========================
   5) CHAT + NEPALI VOICE + AI BOT
========================= */

function appendMsg(type, text){
  const div = document.createElement("div");
  div.className = "msg " + type;
  div.textContent = text;
  chatBox.appendChild(div);
  chatBox.scrollTop = chatBox.scrollHeight;

  // speak bot messages or peer messages if enabled
  if (nepaliVoiceOn && (type === "bot" || type === "peer")) {
    speakNepali(text);
  }
}

function speakNepali(text){
  try {
    const u = new SpeechSynthesisUtterance(text);
    u.lang = "ne-NP"; // will fall back if not available
    window.speechSynthesis.speak(u);
  } catch {}
}

voiceToggleBtn.onclick = () => {
  nepaliVoiceOn = !nepaliVoiceOn;
  voiceToggleBtn.textContent = "Nepali Voice: " + (nepaliVoiceOn ? "ON" : "OFF");
};

function startChatListener(){
  if (!roomRef) return;
  roomRef.child("chat").limitToLast(50).on("child_added", (s) => {
    const m = s.val();
    if (!m) return;
    if (m.from === "me") appendMsg("me", "Me: " + m.text);
    else if (m.from === "peer") appendMsg("peer", "Peer: " + m.text);
    else if (m.from === "bot") appendMsg("bot", "AI: " + m.text);
  });
}

sendBtn.onclick = async () => {
  const text = (chatInput.value || "").trim();
  if (!text) return;
  if (!roomRef) return alert("Join a room first.");

  chatInput.value = "";

  // Determine sender label:
  // Caller writes as "me", callee writes as "peer" (so both sides see consistent roles)
  const from = isCaller ? "me" : "peer";

  await roomRef.child("chat").push({ from, text, at: Date.now() });

  // Ask AI bot (optional)
  // IMPORTANT: do NOT put OpenAI key in browser. Use your server endpoint.
  // You will create an endpoint /api/nepali-bot that returns { reply: "‡§®‡•á‡§™‡§æ‡§≤‡•Ä ‡§â‡§§‡•ç‡§§‡§∞..." }
  try {
    const r = await fetch("/api/nepali-bot", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        roomId: currentRoomId,
        message: text,
        // You can include last messages by reading from Firebase in your backend.
        preferLanguage: "ne"
      })
    });

    if (r.ok) {
      const data = await r.json();
      if (data && data.reply) {
        await roomRef.child("chat").push({ from: "bot", text: data.reply, at: Date.now() });
      }
    }
  } catch {
    // If backend not configured, just ignore silently.
  }
};

/* =========================
   6) QUICK NOTES (IMPORTANT)
========================= */

/*
FIREBASE RULES (simple test only ‚Äî tighten later):
{
  "rules": {
    "webrtcRooms": {
      "$roomId": {
        ".read": true,
        ".write": true
      }
    }
  }
}

AI BOT BACKEND IDEA (Node/Express):
POST /api/nepali-bot
- take message
- call OpenAI (server-side) with instruction: "Reply in Nepali, be helpful."
- return JSON { reply }

This keeps your API key safe.

If you want AI voice BOTH users hear:
- Generate TTS audio server-side and send audio file URL, then both clients play it.
*/
</script>
</body>
</html>
